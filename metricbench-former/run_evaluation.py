from varbench.renderers import TexRenderer, Renderer
from datasets import load_dataset
from metricbench.modifiers import TikzModifier

dataset = load_dataset("CharlyR/varbench", "tikz", split="benchmark")

original_code = dataset["code"][0]

renderer: Renderer = TexRenderer()

new_code = TikzModifier.add_shape(original_code)
with open(".tmp/debug/new_code.tex","w") as new_code_file:
    new_code_file.write(new_code)
with open(".tmp/debug/original_code.tex","w") as original_code_file:
    original_code_file.write(original_code)

original_image = renderer.from_string_to_image(original_code)
new_image = renderer.from_string_to_image(new_code)


original_image.save(".tmp/debug/original.png")
new_image.save(".tmp/debug/new.png")



#Main Idea
""" 
Meh:
Given a solution s, a set of code edits E= [e0,...,ek], 
given a set En[en0,...,enl] with n edits randomly chosen from E,generates variants V1[0..l], with V1i=e'i(s)
Vn[0..n] =An-1(Vn-1) with An()=[Vn-10,Vn-11,...,Vnl]



Take the solution, generate 10 close variants of that solution. 
generate 10 variants of these variants.
select one for each of these ten generations so that we end up with 10 generations(instead of 10*10=100).
do it again and again n times.

we should end up with sets of variants, with the closest to zero being the closest to the initial solution.
Compute the metrics on each set of variants.

Classify manually each of the image generated by answering the question is the modification applied with [yes,no]
find a threshold for each metric that minimizes Type I and type II errors, find the combinaison of metrics that allows to separate 
"""